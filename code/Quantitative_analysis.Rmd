---
title: "DASEH Quantitative Analysis"
output:
  html_document:
    toc: true
  pdf_document:
    toc: true
date: "2025-03-26"
---

# Load Libraries and Data Gathering

```{r}
# Load required libraries
library(tidyverse)     # For data manipulation, plotting, and reshaping
library(googlesheets4) # For reading Google Sheets
library(likert)        # Easy Likert data plotting
library(lme4)          # Modeling summative assessment questions
library(emmeans)       # Some plotting applications for summative assessments
```


This code analyzes data from three surveys and a summative assessment from a two-part data science course (DASEH) for environmental health professionals. The course consists of a 2-week online component and a 3-day in-person intensive codeathon.

It covers two research questions:

**Research Question 1:**
How do students’ self-perception, as measured by comfort and confidence in data science, change over time (pre-course, post-course, and post-codeathon)?

**Research Question 2:**
How does the blended model impact objective learning outcomes measured via a summative assessment?

## Data Wrangling 

```{r}
# Authenticate once
gs4_auth(email = TRUE)

# Google Sheet links
survey_sheet_link <- "https://docs.google.com/spreadsheets/d/1xVDoVb8uTvApd1sYdQBQp6HkCzUPmDunWc82Pk2Rrv0/edit?usp=sharing"
summative_sheet_link <- "https://docs.google.com/spreadsheets/d/13IyHGQ-FnMRgPKO5baAMTCt16UVhY4_ehS_N3ux1o9w/edit?usp=sharing"

# Function to read survey data
get_clean_survey <- function(sheet_name, label) {
  read_sheet(survey_sheet_link, sheet = sheet_name) |>
    rename(random_id = `Random ID`) |>
    mutate(survey = label) |>
    distinct(random_id, survey, .keep_all = TRUE)
}

# Load all surveys
precourse <- get_clean_survey("1 - Pre-course", "1_pre-course")
postcourse <- get_clean_survey("2 - Post-course", "2_post-course") |> filter(!(random_id == "9C8F1953" & Session == 2))
postcodeathon <- get_clean_survey("3 - Post-codeathon", "3_post-codeathon")

# Load summative scores
summative_assessment <- 
  read_sheet(summative_sheet_link, sheet = "4 - Summative Assessment", col_types = "ccnc") |>
  distinct(random_id, survey, question_number, .keep_all = TRUE)
```

## Research Question 1: Self-perception (Likert) - write the data

```{r}
# Pull out Likert items only
precourse_num <- precourse |> select(random_id, 5:19)
postcourse_num <- postcourse |> select(random_id, 3:18)
postcodeathon_num <- postcodeathon |> select(random_id, 3:19)

# Join by ID
daseh_dat <- precourse_num |>
  full_join(postcourse_num, by = "random_id") |>
  full_join(postcodeathon_num, by = "random_id")

# Rename Likert columns
daseh_dat_clean_names <-
  daseh_dat |>
  rename(
    id = "random_id",
    comfort1 = "How would you rate your current comfort with data science, generally?",
    confidence1 = "How confident are you in your ability to use data science tools (e.g., R programming, GitHub) to answer Environmental Health related questions?",
    rmarkdown_1 = "How would you rate your current confidence with these specific tools or topics? [Rmarkdown / Reproducible documents]",
    rstudio_1 = "How would you rate your current confidence with these specific tools or topics? [RStudio]",
    basic_r_1 = "How would you rate your current confidence with these specific tools or topics? [Basic R Syntax]",
    data_import_1 = "How would you rate your current confidence with these specific tools or topics? [Importing or loading data]",
    subsetting_1 = "How would you rate your current confidence with these specific tools or topics? [Subsetting datasets]",
    summarizing_1 = "How would you rate your current confidence with these specific tools or topics? [Summarizing datasets]",
    data_classes_1 = "How would you rate your current confidence with these specific tools or topics? [Data classes]",
    cleaning_1 = "How would you rate your current confidence with these specific tools or topics? [Cleaning datasets]",
    reshaping_1 = "How would you rate your current confidence with these specific tools or topics? [Reshaping or combining datasets]",
    viz_1 = "How would you rate your current confidence with these specific tools or topics? [Data visualization]",
    stats_1 = "How would you rate your current confidence with these specific tools or topics? [Statistics / modeling]",
    func_prog_1 = "How would you rate your current confidence with these specific tools or topics? [Functional programming]",
    github_1 = "How would you rate your current confidence with these specific tools or topics? [Github / version control]",
    comfort2 = "Now that you have taken DaSEH's Online Course, how would you rate your current comfort with data science, generally?",
    confidence2 = "Now that you have taken DaSEH's Online Course, how confident are you in your ability to use data science tools (e.g., R programming, GitHub) to answer Environmental Health related questions?",
    skills_improvement_2 = "Please rate how you feel your skills have improved  as a result of the online course.",
    rmarkdown_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Rmarkdown / Reproducible documents]",
    rstudio_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [RStudio]",
    basic_r_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Basic R Syntax]",
    data_import_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Importing or loading data]",
    subsetting_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Subsetting datasets]",
    summarizing_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Summarizing datasets]",
    data_classes_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Data classes]",
    cleaning_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Cleaning datasets]",
    reshaping_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Reshaping or combining datasets]",
    viz_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Data visualization]",
    stats_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Statistics / modeling]",
    func_prog_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Functional programming]",
    github_2 = "Now that you have taken DaSEH's Online Course, how would you rate your current confidence with these specific tools or topics? [Github / version control]",
    comfort3 = "Now that you have participated in the Code-a-thon, how would you rate your current comfort with data science, generally?",
    confidence3 = "Now that you have participated in the Code-a-thon, how confident are you in your ability to use data science tools (e.g., R programming, GitHub) to answer Environmental Health related questions?",
    skills_improvement_3 = "Please rate how you feel your skills have improved as a result of the Code-a-thon.",
    rmarkdown_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Rmarkdown / Reproducible documents]",
    rstudio_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [RStudio]",
    basic_r_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Basic R Syntax]",
    data_import_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Importing or loading data]",
    subsetting_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Subsetting datasets]",
    summarizing_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Summarizing datasets]",
    data_classes_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Data classes]",
    cleaning_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Cleaning datasets]",
    reshaping_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Reshaping or combining datasets]",
    viz_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Data visualization]",
    stats_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Statistics / modeling]",
    func_prog_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Functional programming]",
    github_3 = "Now that you have participated in the Code-a-thon, how would you rate your current confidence with these specific tools or topics? [Github / version control]",
    recall3 = "The Code-a-thon helped me recall and apply my R skills."
  )

# Convert to numeric
# Make sure values are numeric
daseh_dat_clean <- 
  daseh_dat_clean_names |> 
  mutate(across(
    !id,
    ~ case_when(
      .x == "5 (More confident)" ~ 5,
      .x == "5" ~ 5,
      .x == "4" ~ 4,
      .x == "3" ~ 3,
      .x == "2" ~ 2,
      .x == "1 (Less confident)" ~ 1,
      .x == "1" ~ 1,
      .x == "NULL" ~ NA
    )
  ))

# Save for later
write.csv(daseh_dat_clean, "data/daseh_likert.csv", row.names = FALSE)
```

## Research Question 2: Summative Assessment - write the data

```{r}
# Reshape to wide format
summative_wide <- 
  summative_assessment |> 
  pivot_wider(names_from = question_number, values_from = score, names_prefix = "score_") |>
  arrange(random_id, survey)

# Rename columns
summative_wide <-
  summative_wide |>
  rename(
    id = random_id,
    survey_label = survey,
    Q1 = score_Q1,
    Q2 = score_Q2,
    Q3 = score_Q3
  )

# Save clean version
write.csv(summative_wide, "data/daseh_scores.csv", row.names = FALSE)
```

# RESEARCH QUESTION 1

Research Question 1:
How do students’ self-perception, as measured by comfort and confidence in data science change over time (pre-course, post-course, and post-codeathon)?

## Data Analysis

We asked whether students’ self rated comfort and confidence in data science improves over three timepoints, specifically, pre-course, post-course and post-codeathon.  We used within-subject (paired) tests of median change because learners are likely to have some baseline differences in background.

Before testing, we check normality of the difference scores (Shapiro–Wilk test and QQ plots). If normality assumptions were violated, we use paired two-sample Wilcoxon tests below.

Hypotheses (for both Comfort and Confidence):
	•	H₀: Median change = 0 (no improvement)
	•	Hₐ: Median change > 0 (improvement)

We perform two tests per outcome:
	1.	Pre-course vs Post-course
	2.	Post-course vs Post-codeathon
	
### PART A: Comfort with Data Science

This section analyses self perception, as measured by comfort ratings in data science skills over time (pre-course, post-course and post-codeathon).

Descriptive Statistics

```{r}
# Extract and reshape comfort data
comfort_data <-
  daseh_dat_clean |>
  dplyr::select(id, comfort1, comfort2, comfort3)

# Pivot to long format, recode labels & order
comfort_long <-
  comfort_data |>
  pivot_longer(cols = starts_with("comfort"),
               names_to  = "timepoint",
               values_to = "comfort") |>
  mutate(
    timepoint = dplyr::recode(
      timepoint,
      "comfort1" = "Pre-course",
      "comfort2" = "Post-course",
      "comfort3" = "Post-codeathon"
    ),
    timepoint = factor(
      timepoint,
      levels = c("Pre-course", "Post-course", "Post-codeathon")
    )
  )

# Summary stats at each timepoint
comfort_summary <-
  comfort_long |>
  group_by(timepoint) |>
  summarize(
    mean = mean(comfort, na.rm = TRUE),
    median = median(comfort, na.rm = TRUE),
    sd = sd(comfort, na.rm = TRUE)
  ) |>
  mutate(measure = "comfort") |>
  dplyr::select(measure, timepoint, mean, median, sd)

# Calculate learner-level changes
comfort_change <-
  comfort_data |>
  mutate(
    `Change Post-course` = comfort2 - comfort1,
    `Change Post-codeathon` = comfort3 - comfort2
  ) |>
  dplyr::select(id, starts_with("Change"))

# Pivot changes, recode & order
comfort_change_long <-
  comfort_change |>
  pivot_longer(-id, names_to = "period", values_to = "change") |>
  mutate(period = factor(period, levels = c(
    "Change Post-course", "Change Post-codeathon"
  )))

# Summary stats for change
comfort_change_summary <-
  comfort_change_long |>
  group_by(period) |>
  summarize(
    mean = mean(change, na.rm = TRUE),
    median = median(change, na.rm = TRUE),
    sd = sd(change, na.rm = TRUE)
  )
```

Analytic Statistics

1. Pre-course vs. Post-course:

We test if the change in comfort (Post - Pre) is greater than zero.

H0: The average difference is zero (no improvement).

HA: The average difference is greater than zero.

2. Post-course vs. Post-codeathon:

We test if the change (Post-codeathon - Post) is greater than zero.

H0: The average difference is zero.

HA: The average difference is greater than zero.

Since the same subjects are measured at different times, we calculate the difference for each participant and use a paired t-test (or a non-parametric alternative if normality is violated) on these difference scores.

```{r}
pre_course_comfort <- daseh_dat_clean$comfort1
shapiro.test(pre_course_comfort) # Outcome: not normal

post_course_comfort <- daseh_dat_clean$comfort2
shapiro.test(post_course_comfort) # Outcome: not normal

post_codeathon_comfort <- daseh_dat_clean$comfort3
shapiro.test(post_codeathon_comfort) # Outcome: not normal

comfort_test_course <- broom::tidy(
  wilcox.test(
    daseh_dat_clean$comfort2,
    daseh_dat_clean$comfort1,
    paired = TRUE,
    alternative = "greater"
  )
)
comfort_test_codeathon <- broom::tidy(
  wilcox.test(
    daseh_dat_clean$comfort3,
    daseh_dat_clean$comfort2,
    paired = TRUE,
    alternative = "greater"
  )
)
```

### PART B: Confidence with Data Science

This section analyzes self-perception, as measured by confidence ratings in data science skills over three time points: pre-course, post-course, and post-codeathon.

Descriptive Statistics

```{r}
# Extract and reshape confidence data
confidence_data <- 
  daseh_dat_clean |>
  dplyr::select(id, confidence1, confidence2, confidence3)

# Pivot to long format, recode labels & lock in order
confidence_long <- 
  confidence_data |>
  pivot_longer(
    cols = starts_with("confidence"),
    names_to  = "timepoint",
    values_to = "confidence"
  ) |>
  mutate(
    timepoint = dplyr::recode(timepoint,
      "confidence1" = "Pre-course",
      "confidence2" = "Post-course",
      "confidence3" = "Post-codeathon"
    ),
    timepoint = factor(timepoint,
      levels = c("Pre-course", "Post-course", "Post-codeathon")
    )
  )

# Summary stats at each timepoint
confidence_summary <-
  confidence_long |>
  group_by(timepoint) |>
  summarize(
    mean   = mean(confidence, na.rm = TRUE),
    median = median(confidence, na.rm = TRUE),
    sd     = sd(confidence, na.rm = TRUE)
  ) |>
  mutate(measure = "confidence") |> 
  dplyr::select(measure, timepoint, mean, median, sd)

# Calculate learner-level changes
confidence_change <- 
  confidence_data |>
  mutate(
    `Change Post-course`       = confidence2 - confidence1,
    `Change Post-codeathon`  = confidence3 - confidence2
  ) |>
  dplyr::select(id, starts_with("Change"))

# Pivot changes, recode & lock in order
confidence_change_long <- 
  confidence_change |>
  pivot_longer(-id, names_to = "period", values_to = "change") |>
  mutate(
    period = factor(period,
      levels = c("Change Post-course", "Change Post-codeathon")
    )
  )

# Summary stats for change in confidence
confidence_change_summary <- 
  confidence_change_long |>
  group_by(period) |>
  summarize(
    mean   = mean(change, na.rm = TRUE),
    median = median(change, na.rm = TRUE),
    sd     = sd(change, na.rm = TRUE)
  )
```

Analytic Statistics 

Test whether the change in confidence from pre-course to post-course is greater than zero.

H₀: The difference equals zero (no improvement).

Hₐ: The difference is greater than zero.

Test whether the change in confidence from post-course to post-codeathon is greater than zero.

H₀: The difference equals zero.

Hₐ: The difference is greater than zero.

Since the same subjects are measured at different times, we calculate the difference for each participant and use a paired t-test (or a non-parametric alternative if normality is violated) on these difference scores.

```{r}
pre_course_confidence <- daseh_dat_clean$confidence1
shapiro.test(pre_course_confidence) # Outcome: not normal

post_course_confidence <- daseh_dat_clean$confidence2
shapiro.test(post_course_confidence) # Outcome: not normal

post_codeathon_confidence <- daseh_dat_clean$confidence3
shapiro.test(post_codeathon_confidence) # Outcome: not normal

confidence_test_course <- broom::tidy(
  wilcox.test(
    daseh_dat_clean$confidence2,
    daseh_dat_clean$confidence1,
    paired = TRUE,
    alternative = "greater"
  )
)
confidence_test_codeathon <- broom::tidy(
  wilcox.test(
    daseh_dat_clean$confidence3,
    daseh_dat_clean$confidence2,
    paired = TRUE,
    alternative = "greater"
  )
)
```

Gather statistical finding for the paper:

```{r}
rbind(
  comfort_summary,
  confidence_summary
)

# Print results with p-adjustment
rbind(
  comfort_test_course,
  comfort_test_codeathon,
  confidence_test_course,
  confidence_test_codeathon
) |> 
  mutate(p.adj = p.adjust(p.value)) |> 
  dplyr::select(statistic, p.value, p.adj)
```

### PART C: Skills Improvement

In this part, there is no pre-course rating. We report summary statistics for skills improvement after the online course (Survey 2) and after the codeathon (Survey 3).

```{r}
# Extract and reshape skills improvement data
skills_data <- daseh_dat_clean |>
  dplyr::select(id, skills_improvement_2, skills_improvement_3)

skills_long <- skills_data |>
  pivot_longer(
    cols      = starts_with("skills_improvement"),
    names_to  = "timepoint",
    values_to = "rating"
  ) |>
  mutate(
    timepoint = dplyr::recode(timepoint,
      "skills_improvement_2" = "Post-course",
      "skills_improvement_3" = "Post-codeathon"
    ),
    timepoint = factor(timepoint,
      levels = c("Post-course", "Post-codeathon")
    )
  )

# Summary stats at each timepoint
skills_stats <- skills_long |>
  group_by(timepoint) |>
  summarize(
    mean   = mean(rating, na.rm = TRUE),
    median = median(rating, na.rm = TRUE),
    sd     = sd(rating, na.rm = TRUE)
  )

# Print stats for the paper
skills_stats
```

### LIKERT PLOTS 

Make a combined likert that is slightly more readable (bigger text).

```{r}
the_labels <- list(comfort = "\nPerceived\ncomfort", confidence = "\nPerceived\nconfidence")

likert_items <- names(the_labels)

make_likert_plot <- function(item, dat, make_hist = F) {
  cols <- paste0(item, c("1", "2", "3"))
  print(cols %in% names(dat))
  
  likert_item <- dat |> select(all_of(cols))
  names(likert_item) <- c("Pre-course", "Post-course", "Post-codeathon")
  
  likert_item[] <- lapply(likert_item, function(x) {
    factor(as.character(x), levels = c("1", "2", "3", "4", "5"))
  })
  
  likert_obj <- likert(as.data.frame(likert_item))
  
  if (!make_hist) {
    likert.bar.plot(likert_obj, ordered = FALSE) +
      theme(
        axis.ticks = element_blank(),
        strip.background = element_rect(fill = '#F0F0F0', color = '#F0F0F0'),
        panel.background = element_rect(
          size = 1,
          color = 'grey70',
          fill = NA
        ),
        legend.position = "none",
        axis.text.x = element_blank(),
        axis.title.y = element_text(
          size = 11,
          angle = 0,
          vjust = 0.8
        ),
        plot.margin = unit(c(0, 0, 0, 0.5), "cm")
      ) + ylab(NULL) + xlab(the_labels[[item]])
  } else {
    likert.histogram.plot(likert_obj, text.size = 3,order = rev(names(likert_item))) +
      theme(
        axis.ticks = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        strip.background = element_rect(fill = '#F0F0F0', color = '#F0F0F0'),
        panel.background = element_rect(
          size = 1,
          color = 'grey70',
          fill = NA
        ),
        legend.position = "none",
        axis.text.x = element_blank()
      ) + ylab(NULL) + xlab(NULL)
  }
}

likert_plots <- lapply(likert_items, make_likert_plot, dat = daseh_dat_clean)
hist_plots <- lapply(likert_items,
                     make_likert_plot,
                     dat = daseh_dat_clean,
                     make_hist = T)

#Figure 3 in manuscript
pdf("figures/likert_comfort_confidence.pdf", width = 7, height = 4)
cowplot::plot_grid(
  likert_plots[[1]] + theme(
        plot.margin = unit(c(0, 0, 0, 0), "mm")),
  hist_plots[[1]] + theme(
        plot.margin = unit(c(0, 0, 0, 2), "mm")),
  ggplot() + theme_void(),
  ggplot() + theme_void(),
  likert_plots[[2]]  +
    theme(
      legend.position = c(-0.1,-0.5),
      axis.text.x = element_text(),
      legend.direction = "horizontal",
      legend.justification = "left",
      plot.margin = unit(c(0, 0, 15, 0), "mm")
    ) +
    ylab("Percentage"),
  hist_plots[[2]] +
    theme(
      legend.position = c(0,-0.5),
      legend.justification = "center",
      legend.direction = "horizontal",
      axis.text.x = element_text(),
      plot.margin = unit(c(0, 0, 15, 2), "mm")
    ) +
    ylab("Sample size"),
  ncol = 2,
  align = "h",
  labels = c("(a)", rep("", 3), "(b)", rep("", 1)),
  rel_heights = c(1, -0.3, 1),
  rel_widths = c(1, 0.2)
  #
)
dev.off()
```

How do students’ self-perception, as measured by confidence BY TOPIC change over time?

```{r}
tool_labels <- list(
  rmarkdown = "RMarkdown",
  rstudio = "RStudio",
  basic_r = "Base R",
  github = "GitHub",
  cleaning = "Data\nCleaning",
  data_classes = "Data\nClasses",
  data_import = "Data\nImport",
  subsetting = "Subsetting",
  summarizing = "Summarizing",
  reshaping = "Reshaping",
  viz = "Visualization",
  stats = "Statistics",
  func_prog = "Functional\nProgramming"
)

tools_all <- names(tool_labels)

make_likert_plot <- function(tool, dat) {
  cols <- paste0(tool, c("_1", "_2", "_3"))
  print(cols %in% names(dat))
  
  likert_tool <- dat |> select(all_of(cols))
  names(likert_tool) <- c("Pre-course", "Post-course", "Post-codeathon")
  
  likert_tool[] <- lapply(likert_tool, function(x) {
    factor(as.character(x), levels = c("1", "2", "3", "4", "5"))
  })
  
  likert_obj <- likert(as.data.frame(likert_tool))
  
  likert.bar.plot(likert_obj, ordered = FALSE) +
    theme(
      axis.ticks = element_blank(),
      strip.background = element_rect(fill = '#F0F0F0', color = '#F0F0F0'),
      panel.background = element_rect(
        size = 1,
        color = 'grey70',
        fill = NA
      ),
      legend.position = "none",
      axis.text.x = element_blank(),
      axis.title.y = element_text(
        size = 11,
        angle = 0,
        vjust = 0.8
      ),
      plot.margin = unit(c(0, 0, 0, 1), "cm")
    ) + ylab(NULL) + xlab(tool_labels[[tool]])
}

likert_plots <- lapply(tools_all, make_likert_plot, dat = daseh_dat_clean)

#Figure 3 in manuscript
pdf("figures/likert_confidence_bytopic.pdf", width = 8, height = 9.5)
cowplot::plot_grid(
  likert_plots[[1]],
  likert_plots[[2]],
  likert_plots[[4]],
  ggplot() + theme_void(),
  likert_plots[[3]],
  likert_plots[[5]],
  likert_plots[[6]],
  likert_plots[[7]],
  likert_plots[[8]],
  likert_plots[[9]],
  likert_plots[[10]],
  likert_plots[[11]],
  likert_plots[[12]],
  likert_plots[[13]] + theme(legend.position = "bottom", axis.text.x = element_text()) + ylab("Percentage"),
  ncol = 1,
  align = "v",
  labels = c("(a)", rep("", 3), "(b)", rep("", 10)),
  rel_heights = c(rep(1, 3), 0.4, rep(1, 9), 2.3)
)
dev.off()
```


# RESEARCH QUESTION 2:

How do blended models impact objective learning outcomes measured via a summative assessment?

The script uses the following libraries:

In this analysis, we used a linear mixed effects model (LMM) to evaluate changes in participants’ summative assessment scores over time for every question.

By using a linear mixed effects model, we retain more data, properly model individual variation.

Fit Models by Question (Q1, Q2, Q3)

```{r}
library(lmerTest)

model_q1 <- lmer(score ~ survey +  (1 | random_id),
                 data = summative_assessment |> filter(question_number == "Q1"))
model_q1_out <- coef(summary(model_q1))

model_q2 <- lmer(score ~ survey +  (1 | random_id),
                 data = summative_assessment |> filter(question_number == "Q2"))
model_q2_out <- coef(summary(model_q2))

model_q3 <- lmer(score ~ survey +  (1 | random_id),
                 data = summative_assessment |> filter(question_number == "Q3"))
model_q3_out <- coef(summary(model_q3))

summative_stats <-
  as_tibble(rbind(model_q1_out, model_q2_out, model_q3_out)) |>
  mutate(Question = c(
    rep("Data Cleaning and Preprocessing", 3),
    rep("Reproducibility and Workflow Practices", 3),
    rep("Analytical Reasoning and Data Exploration", 3))
  ) |>
  mutate(Timepoint = rep(c("Intercept", "Post-course", "Post-codeathon"), times = 3)) |>
  relocate(Question, .before = Estimate) |>
  relocate(Timepoint, .before = Estimate) |>
  mutate(adj.p = p.adjust(`Pr(>|t|)`))
```

EMM Plots 

```{r}
# Map of question titles
question_labels <- c(
  score_Q1 = "Data cleaning & preprocessing",
  score_Q2 = "Reproducibility & workflow",
  score_Q3 = "Analytical reasoning & data exploration"
)

plot_emm_simple <- function(model, label) {
  emm_df <- as_tibble(emmeans(model, specs = "survey"))

  # Print levels to confirm if needed
  # print(unique(emm_df$survey))

  # Proper relabeling using factor() with correct levels
  emm_df <- emm_df |>
    mutate(
      survey = factor(
        survey,
        levels = c("1_pre-course", "2_post-course", "3_post-codeathon"),
        labels = c("Pre-course", "Post-course", "Post-codeathon")
      )
    )

  ggplot(emm_df, aes(x = survey, y = emmean, group = 1)) +
    geom_line(size = 1.2) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.1) +
    labs(
      title = label,
      x = NULL,
      y = "Predicted Score"
    ) +
    theme(plot.title = element_text(face = "bold", hjust = 0.5))
}
# Generate and save individual plots
p_q1 <- plot_emm_simple(model_q1, question_labels[["score_Q1"]])
p_q2 <- plot_emm_simple(model_q2, question_labels[["score_Q2"]])
p_q3 <- plot_emm_simple(model_q3, question_labels[["score_Q3"]])
```

Make combined plots for all question domains

```{r echo=F}
library(patchwork)
# The following code not printed

make_theme <- function(in_plot) {
  in_plot +
    theme(
      axis.ticks = element_blank(),
      strip.background = element_rect(fill = '#F0F0F0', color = '#F0F0F0'),
      panel.background = element_rect(
        size = 1,
        color = 'grey70',
        fill = NA
      ),
      legend.position = "none",
      plot.margin = unit(c(0, 0, 0, 0), "cm")
    )
}

p_q1 <- make_theme(p_q1)
p_q2 <- make_theme(p_q2)
p_q3 <- make_theme(p_q3)

# Combine vertically (stacked) (Figure 5 in manuscript)
p_combined_vertical <- p_q1 / p_q2 / p_q3
ggsave(
  filename = "figures/emm_combined_vertical.png",
  plot = p_combined_vertical,
  width = 4,
  height = 7,
  dpi = 300
)

### All together, but faceted instead
emm_df_all <-
  as_tibble(emmeans(model_q1, specs = "survey")) |>
  mutate(question = "1_Data cleaning & preprocessing") |>
  bind_rows(as_tibble(emmeans(model_q2, specs = "survey")) |>
              mutate(question = "2_Reproducibility & workflow practice")) |>
  bind_rows(as_tibble(emmeans(model_q3, specs = "survey")) |>
              mutate(question = "3_Analytical reasoning & data exploration")) |>
  mutate(survey = factor(
    survey,
    levels = c("1_pre-course", "2_post-course", "3_post-codeathon"),
    labels = c("Pre-course", "Post-course", "Post-codeathon")
  )) |>
  mutate(question = factor(
    question,
    levels = c(
      "1_Data cleaning & preprocessing",
      "2_Reproducibility & workflow practice",
      "3_Analytical reasoning & data exploration"
    ),
    labels = c(
      "Data cleaning & preprocessing",
      "Reproducibility & workflow practice",
      "Analytical reasoning & data exploration"
    )
  ))

p_combined_vertical <- 
  make_theme(
  ggplot(emm_df_all, aes(
    x = survey, y = emmean, group = 1
  )) +
    geom_line(size = 1.2) +
    geom_point(size = 3) +
    geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.1) +
    labs(x = NULL, y = "Predicted Score") +
    facet_wrap( ~ question, ncol = 1)
)

ggsave(
  filename = "figures/emm_combined_vertical.png",
  plot = p_combined_vertical,
  width = 4,
  height = 7,
  dpi = 300
)
```

